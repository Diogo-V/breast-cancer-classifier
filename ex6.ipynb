{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import definition\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Constants definition\n",
    "GROUP_NUMBER = 16  # Our group number\n",
    "NEIGHBOURS = [3, 5, 7]  # Number of neighbours to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Loading dataset into working desk\n",
    "data = arff.loadarff('breast.w.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "# Removes NaN values from dataset by deleting rows\n",
    "df.dropna(axis=0, how=\"any\", inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Gets X (data matrix) and y (target values column matrix)\n",
    "X = df.drop(\"Class\", axis=1).to_numpy()\n",
    "y = df[\"Class\"].to_numpy()\n",
    "\n",
    "# Performs some preprocessing by turning labels into binaries (benign is 1)\n",
    "# We are doing a \"double conversion\" to convert everything to Binary type\n",
    "for count, value in enumerate(y):\n",
    "    if value == b\"benign\":\n",
    "        y[count] = \"yes\"\n",
    "    else:\n",
    "        y[count] = \"no\"\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying n = 3:\n",
      "Acc using test data 0.957\n",
      "Acc using training data 0.985\n",
      "Acc using test data 0.971\n",
      "Acc using training data 0.982\n",
      "Acc using test data 0.971\n",
      "Acc using training data 0.980\n",
      "Acc using test data 0.971\n",
      "Acc using training data 0.979\n",
      "Acc using test data 0.956\n",
      "Acc using training data 0.980\n",
      "Acc using test data 0.971\n",
      "Acc using training data 0.977\n",
      "Acc using test data 0.971\n",
      "Acc using training data 0.980\n",
      "Acc using test data 0.971\n",
      "Acc using training data 0.979\n",
      "Acc using test data 0.985\n",
      "Acc using training data 0.977\n",
      "Acc using test data 0.985\n",
      "Acc using training data 0.979\n",
      "Training acc: 0.980\n",
      "Test acc: 0.971\n",
      "Diff: 0.009\n",
      "RMSE: 0.014\n",
      "\n",
      "\n",
      "Classifying n = 5:\n",
      "Acc using test data 0.957\n",
      "Acc using training data 0.985\n",
      "Acc using test data 0.971\n",
      "Acc using training data 0.982\n",
      "Acc using test data 0.971\n",
      "Acc using training data 0.980\n",
      "Acc using test data 0.985\n",
      "Acc using training data 0.980\n",
      "Acc using test data 0.985\n",
      "Acc using training data 0.980\n",
      "Acc using test data 0.971\n",
      "Acc using training data 0.984\n",
      "Acc using test data 0.985\n",
      "Acc using training data 0.982\n",
      "Acc using test data 0.985\n",
      "Acc using training data 0.979\n",
      "Acc using test data 0.971\n",
      "Acc using training data 0.979\n",
      "Acc using test data 0.985\n",
      "Acc using training data 0.977\n",
      "Training acc: 0.981\n",
      "Test acc: 0.977\n",
      "Diff: 0.004\n",
      "RMSE: 0.012\n",
      "\n",
      "\n",
      "Classifying n = 7:\n",
      "Acc using test data 0.942\n",
      "Acc using training data 0.980\n",
      "Acc using test data 0.986\n",
      "Acc using training data 0.980\n",
      "Acc using test data 0.986\n",
      "Acc using training data 0.982\n",
      "Acc using test data 0.971\n",
      "Acc using training data 0.979\n",
      "Acc using test data 0.956\n",
      "Acc using training data 0.977\n",
      "Acc using test data 0.971\n",
      "Acc using training data 0.982\n",
      "Acc using test data 0.971\n",
      "Acc using training data 0.977\n",
      "Acc using test data 0.985\n",
      "Acc using training data 0.979\n",
      "Acc using test data 0.985\n",
      "Acc using training data 0.976\n",
      "Acc using test data 0.985\n",
      "Acc using training data 0.977\n",
      "Training acc: 0.979\n",
      "Test acc: 0.974\n",
      "Diff: 0.005\n",
      "RMSE: 0.016\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We need to create a classifier for each number of neighbours\n",
    "for n in NEIGHBOURS:\n",
    "\n",
    "    # Holds training and testing accuracy to be latter used to determine which K is more susceptible to over fit\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "\n",
    "    print(f\"Classifying n = {n}:\")\n",
    "\n",
    "    # Creates a k fold cross validator\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=GROUP_NUMBER)\n",
    "\n",
    "    # Creates KNN classifier for n neighbours\n",
    "    clf = KNeighborsClassifier(n, weights=\"uniform\", p=2, metric=\"minkowski\")\n",
    "\n",
    "    # For each train/test set, we use a KNN classifier\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "        # Uses indexes to fetch which values are going to be used to train and test\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Trains knn classifier\n",
    "        clf.fit(X_train, y_train.ravel())\n",
    "\n",
    "        # Uses testing data and gets model accuracy\n",
    "        acc = clf.score(X_test, y_test)\n",
    "        test_acc.append(acc)\n",
    "        print(\"Acc using test data {:.3f}\".format(acc))\n",
    "\n",
    "        # Uses training data and gets model accuracy to determine over fitting\n",
    "        acc = clf.score(X_train, y_train)\n",
    "        train_acc.append(acc)\n",
    "        print(\"Acc using training data {:.3f}\".format(acc))\n",
    "\n",
    "    # Calculates means for train and test to determine which one is over fitting less\n",
    "    train_mean = sum(train_acc) / 10\n",
    "    test_mean = sum(test_acc) / 10\n",
    "    error = math.sqrt(np.square(np.subtract(train_acc, test_acc)).mean())\n",
    "    print(\"Training acc: {:.3f}\".format(train_mean))\n",
    "    print(\"Test acc: {:.3f}\".format(test_mean))\n",
    "    print(\"Diff: {:.3f}\".format(train_mean - test_mean))\n",
    "    print(\"RMSE: {:.3f}\".format(error))\n",
    "\n",
    "    print(\"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}